{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5384072-7226-4220-8a4a-9b0c209a39f2",
   "metadata": {},
   "source": [
    "## Project 3 - Subreddit \n",
    "### by Steven Tran\n",
    "\n",
    "<span style='color: red;'>Add TOC when available</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30783d8b-4c63-4f1d-ae2b-6f8f51df4915",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 01: Data Collection\n",
    "\n",
    "In this notebook, I will collect (X) number of posts from two subreddits. The table below describes the two subredits, and the date range from which user posts were collected:\n",
    "\n",
    "| Subreddit | # of user posts | FROM | TO |\n",
    "|-----------|-----------------|------|----|\n",
    "| [Sub1](#)      |                 |      |    |\n",
    "| [Sub2](#)      |                 |      |    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d0e132c-d9db-4dba-94be-4dc1056c0647",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T03:43:20.269389Z",
     "iopub.status.busy": "2021-10-29T03:43:20.269389Z",
     "iopub.status.idle": "2021-10-29T03:43:20.285055Z",
     "shell.execute_reply": "2021-10-29T03:43:20.285055Z",
     "shell.execute_reply.started": "2021-10-29T03:43:20.269389Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests, time, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "175e8afa-c739-4f65-aa4d-ec7fa77f695a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T05:46:44.568070Z",
     "iopub.status.busy": "2021-10-29T05:46:44.568070Z",
     "iopub.status.idle": "2021-10-29T05:46:44.583668Z",
     "shell.execute_reply": "2021-10-29T05:46:44.583668Z",
     "shell.execute_reply.started": "2021-10-29T05:46:44.568070Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#access pushshift api to get reddit posts:\n",
    "base_url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "def get_posts(subreddit, num_valid_posts = 200):\n",
    "    #define some boundaries:\n",
    "    target_valid_posts = num_valid_posts #200 by default\n",
    "    count_posts_collected = 0\n",
    "    beginning_date = 1609459200 # jan 1 2021 00:00:00 # start at this date and go back in time; UTC\n",
    "    final_df = pd.DataFrame()\n",
    "    times_run = 0\n",
    "    seconds_waited = 0\n",
    "    \n",
    "    \n",
    "    #check if the subreddit is valid:\n",
    "    check_params = {\n",
    "        'subreddit': subreddit,\n",
    "        'size': 0,\n",
    "        'metadata': 'true'\n",
    "    }\n",
    "\n",
    "    if requests.get(base_url,check_params).json()['metadata']['total_results'] > target_valid_posts:\n",
    "        #initial parameters:\n",
    "        params = {\n",
    "            'subreddit': subreddit,\n",
    "            'size': 100,\n",
    "            'before': beginning_date\n",
    "        }\n",
    "        \n",
    "        while count_posts_collected < target_valid_posts:\n",
    "            #get posts:\n",
    "            res = requests.get(base_url,params).json()['data']\n",
    "            this_data = pd.DataFrame(res)[['id','subreddit','title','selftext','created_utc']]\n",
    "\n",
    "            #get new time (needs to happen before a bunch of rows get removed):\n",
    "            new_time = list(this_data['created_utc'])[-1]\n",
    "            \n",
    "            # drop removed and deleted:\n",
    "            this_data.drop(this_data[this_data['selftext']=='[removed]'].index, inplace=True)\n",
    "            this_data.drop(this_data[this_data['selftext']=='[deleted]'].index, inplace=True)\n",
    "            \n",
    "            #append new posts:\n",
    "            if final_df.shape[0] == 0:\n",
    "                final_df = this_data\n",
    "            else:\n",
    "                final_df = pd.concat([final_df,this_data])\n",
    "           \n",
    "            #get new size:\n",
    "            count_posts_collected += this_data.shape[0]\n",
    "            new_size = min(target_valid_posts - count_posts_collected,100)\n",
    "\n",
    "            #set new params:\n",
    "            params = {\n",
    "                'subreddit': subreddit,\n",
    "                'size': new_size,\n",
    "                'before': new_time,                  \n",
    "            }\n",
    "            \n",
    "            #wait a bit before we go again:\n",
    "            time.sleep(10)\n",
    "            seconds_waited += 10\n",
    "            times_run += 1\n",
    "        \n",
    "    else:\n",
    "        print(f'Error, {subreddit} did not have enough posts to be considered.')\n",
    "    print()\n",
    "    print(f'Went out to get posts {times_run} times. Waited {seconds_waited} seconds or {seconds_waited/60:.1f} minutes.')\n",
    "    return final_df\n",
    "\n",
    "def get_metadata(subreddit):\n",
    "    meta_params = {\n",
    "        'subreddit': subreddit,\n",
    "        'size': 0,\n",
    "        'metadata': 'true'\n",
    "    }\n",
    "    \n",
    "    res = requests.get(base_url, meta_params)\n",
    "    sub_metadata = res.json()['metadata']\n",
    "    return {'sub_metadata': sub_metadata}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a4097-0e74-48e7-b28d-980d05eef408",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "A few contenders for subreddits we'll include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6d35865-d30d-4d63-b8bf-5c8c48c5f0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T05:50:20.375762Z",
     "iopub.status.busy": "2021-10-29T05:50:20.375762Z",
     "iopub.status.idle": "2021-10-29T06:10:19.061727Z",
     "shell.execute_reply": "2021-10-29T06:10:19.061727Z",
     "shell.execute_reply.started": "2021-10-29T05:50:20.375762Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Went out to get posts 111 times. Waited 1110 seconds or 18.5 minutes.\n"
     ]
    }
   ],
   "source": [
    "#movies:\n",
    "movies = (get_posts('movies', 8_000), get_metadata('movies'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
